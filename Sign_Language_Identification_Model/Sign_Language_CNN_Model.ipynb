{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Sign Language Digits with CNN\n",
    "\n",
    "We'll build a ConvNet that can differentiate between 6 sign language digits, going from 0 to 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from tensorflow.python.framework import ops\n",
    "from PIL import Image\n",
    "\n",
    "from cnn_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1. Dataset\n",
    "\n",
    "<a name='1.1'></a>\n",
    "### 1.1 - Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_signs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/SIGNS.png\" width=\"60%\" lenght=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an image from the dataset\n",
    "index = 0\n",
    "plt.imshow(X_train_orig[index])\n",
    "plt.title(\"y = \" + str(np.squeeze(Y_train_orig[:, index])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the input data\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Converting Y to its one-hot representation\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print()\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Model architecture\n",
    "\n",
    "We'll implement the following architecture to build our model:\n",
    "\n",
    "`Conv2D -> ReLU -> MaxPool -> Conv2D -> ReLU -> MaxPool -> Flatten -> Dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58643806aa8380c96225fc8b4c5e7aa",
     "grade": false,
     "grade_id": "cell-dac51744a9e03f51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model.\n",
    "    \n",
    "    Arguments:\n",
    "    input_img -- input dataset, of shape 'input_shape'\n",
    "    parameters -- dict containing cnn layers parameters\n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieving paramenters\n",
    "    n1, n2 = parameters['n1'], parameters['n2']\n",
    "    f1, f2 = parameters['f1'], parameters['f2']\n",
    "    mp_f1, mp_f2 = parameters['mp_f1'], parameters['mp_f2']\n",
    "    mp_s1, mp_s2 = parameters['mp_s1'], parameters['mp_s2']\n",
    "    n = parameters['n_s']\n",
    "    \n",
    "    # Input\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First block\n",
    "    Z1 = tfl.Conv2D(n1, f1, padding='same')(input_img)\n",
    "    A1 = tfl.ReLU()(Z1)\n",
    "    P1 = tfl.MaxPooling2D(pool_size=(mp_f1,mp_f1), strides=mp_s1, padding='same')(A1)\n",
    "    \n",
    "    # Second block\n",
    "    Z2 = tfl.Conv2D(n2, f2, padding='same')(P1)\n",
    "    A2 = tfl.ReLU()(Z2)\n",
    "    P2 = tfl.MaxPooling2D(pool_size=(mp_f2,mp_f2), strides=mp_s2, padding='same')(A2)\n",
    "    \n",
    "    # Output\n",
    "    F = tfl.Flatten()(P2)\n",
    "    outputs = tfl.Dense(n, activation='softmax')(F)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the dataset in minibatches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting parameters\n",
    "parameters = {}\n",
    "\n",
    "# block 1\n",
    "parameters['n1'] = 8\n",
    "parameters['f1'] = 4\n",
    "parameters['mp_f1'] = 8 \n",
    "parameters['mp_s1'] = 8\n",
    "\n",
    "# block 2\n",
    "parameters['n2'] = 16\n",
    "parameters['f2'] = 2\n",
    "parameters['mp_f2'] = 4\n",
    "parameters['mp_s2'] = 4\n",
    "\n",
    "# output \n",
    "parameters['n_s'] = Y_train.shape[1]\n",
    "\n",
    "model = convolutional_model(X_train.shape[1:], parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fittig the model \n",
    "history = model.fit(train_dataset, epochs=500, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking history\n",
    "df_loss_acc = pd.DataFrame(history.history)\n",
    "\n",
    "df_loss = df_loss_acc[['loss','val_loss']].copy()\n",
    "df_loss.rename(columns = {'loss':'train', 'val_loss':'validation'}, inplace=True)\n",
    "\n",
    "df_acc = df_loss_acc[['accuracy','val_accuracy']].copy()\n",
    "df_acc.rename(columns = {'accuracy':'train', 'val_accuracy':'validation'}, inplace=True)\n",
    "\n",
    "# Plotting loss\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(df_loss)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('')\n",
    "\n",
    "# Plotting accuracy\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(df_acc)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Results\n",
    "\n",
    "Sign languages digits with red legends indicate that the model wasn't able to corretly predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 5\n",
    "\n",
    "# Selecting random instances from X_test\n",
    "random = list(np.random.randint(0, high=X_test.shape[0] + 1, size=n_rows*n_cols, dtype=int))\n",
    "test = X_test[random,:,:,:]\n",
    "\n",
    "# Predicting the output from above selection\n",
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "# Comparing the results\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(4*n_cols, 4*n_rows))\n",
    "ax = ax.reshape((n_rows*n_cols,))\n",
    "\n",
    "for i in range(n_rows*n_cols):\n",
    "    ax[i].imshow(test[i,:,:,:])\n",
    "    \n",
    "    if int(np.squeeze(Y_test_orig[0, random[i]])) == pred[i]:\n",
    "        ax[i].set_xlabel(pred[i], fontsize=14, color='k')\n",
    "    \n",
    "    else:\n",
    "        ax[i].set_xlabel(pred[i], fontsize=14, color='r')\n",
    "        \n",
    "    ax[i].grid(False)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    \n",
    "# plt.subplots_adjust(wspace = 0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "deep_venv",
   "language": "python",
   "name": "deep_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

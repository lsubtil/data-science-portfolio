{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Driving - Car's Detection System\n",
    "\n",
    "We will build a car's detection system using a pre-trained YOLO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yad2k.utils.utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Model Details\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Dataset\n",
    "- The model was trained using road pictures collected by a camera mounted to the hood of a car.\n",
    "- All the images were labelled with bounding boxes around every object found. Here's an example:\n",
    "\n",
    "<center> <img src=\"images/box_label.png\" width=\"45%\" height=\"45%\"> </center>\n",
    "<caption> <center> <b>Figure 1</b>: Definition of a box </center></caption>\n",
    "<br>  \n",
    " \n",
    "<a name='1-2'></a>\n",
    "### 1.2 - Inputs and Outputs\n",
    "- It was used images with shape of (608, 608, 3), for training the model.\n",
    "\n",
    "- The output is a list of bounding boxes along with the recognized classes. Each bounding box is represented by 6 numbers $(p_c, b_x, b_y, b_h, b_w, c)$, as showed in **figure 1**. Since the model is capable of recognizing 80 diferent classes, $c$ is an 80-dimensional vector. So each bounding box is represented by 85 numbers. \n",
    "\n",
    "<a name='1-3'></a>\n",
    "### 1.3 - Anchor boxes\n",
    "- Anchor boxes were chosen by exploring the training data to select reasonable height/width ratios that represent the different classes. 5 anchor boxes were chosen, and stored in the file './model_data/yolo_anchors.txt'.\n",
    "    \n",
    "- If the center/midpoint of an object falls into a grid cell, that grid cell is responsible for detecting that object.\n",
    "    \n",
    "<center> <img src=\"images/architecture.png\" width=\"60%\" height=\"60%\"> <center>\n",
    "<caption> <center> <b> Figure 2 </b>: Encoding architecture for YOLO </center> </caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each box (of each cell) the probability of contain a certain class ($score_{c,i}$) is the probability that there is an object ($p_{c}$) times the probability that the object is a certain class ($c_{i}$).\n",
    "\n",
    "<center> <img src=\"images/probability_extraction.png\" width=\"50%\" height=\"50%\"> </center>\n",
    "<caption> <center> <b> Figure 3 </b>: Finding the class detected by each box </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Building the System\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - Non-max Suppression\n",
    "Even though for one object, the recognition is a task for just one anchor box, it's possible that more than one is identifying the same object in the figure. To reduce the model's output to a much smaller number of detected objects, we'll use the non-max suppression method. The steps are:\n",
    "\n",
    "- Get rid of boxes with a low score by apllying a threshold.\n",
    "- Select only one box from overlaping boxes detecting the same object. This step is applied using a function called Intersection over Union, or IoU.\n",
    "\n",
    "<center> <img src=\"images/iou.png\" width=\"50%\" height=\"50%\"> </center>\n",
    "<caption> <center> <b> Figure 4 </b>: Definition of \"Intersection over Union\".</center> </caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a funtion to filter the bounding boxes based on its calculated scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-125a819999f836d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "        boxes -- tensor of shape (19, 19, 5, 4), boxes corners coordinates\n",
    "        box_confidence -- tensor of shape (19, 19, 5, 1), propability of containing an object for each box\n",
    "        box_class_probs -- tensor of shape (19, 19, 5, 80), classes probabilities for each box\n",
    "        threshold -- real value, score threshold\n",
    "\n",
    "    Returns:\n",
    "        scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "        boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "        classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "\n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating the score for each box\n",
    "    box_scores = box_confidence*box_class_probs\n",
    "    \n",
    "    # Selecting the most probable class for each box  \n",
    "    box_classes = tf.math.argmax(box_scores, axis=-1)\n",
    "    \n",
    "    # Selecting the biggest score for each box \n",
    "    box_class_scores = tf.math.reduce_max(box_scores, axis=-1)\n",
    "    \n",
    "    # Creating mask for filtering \n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "    \n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask) # filtering scores\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask) # filtering boxes\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask) # filtering classes\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43008d769892f26f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Implement the intersection over union (IoU) between box1 and box2\n",
    "    \n",
    "    Arguments:\n",
    "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
    "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
    "    \"\"\"\n",
    "\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "\n",
    "    # Calculating union area \n",
    "    # Union(A,B) = A + B - Inter(A,B)\n",
    "    \n",
    "    # Inter(A,B)\n",
    "    xi1 = max(box1_x1, box2_x1)\n",
    "    yi1 = max(box1_y1, box2_y1)\n",
    "    xi2 = min(box1_x2, box2_x2)\n",
    "    yi2 = min(box1_y2, box2_y2)\n",
    "    \n",
    "    inter_width = max((xi2 - xi1),0)\n",
    "    inter_height =  max((yi2 - yi1),0)\n",
    "    \n",
    "    inter_area = inter_width*inter_height\n",
    "    \n",
    "    #  A e B\n",
    "    box1_area = (box1_x2 - box1_x1)*(box1_y2 - box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1)*(box2_y2 - box2_y1)\n",
    "    \n",
    "    # Union(A,B)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # Calculating the IoU\n",
    "    iou = inter_area/union_area\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has a built-in function that is used to implement non-max suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45dde3252e543bbd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, classes, max_boxes=10, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Applies non-max suppression to set of boxes\n",
    "    \n",
    "    Arguments:\n",
    "    boxes --  tensor of shape (num_boxes, 4), boxes corners coordinates \n",
    "    scores -- tensor of shape (num_boxes), boxes scores\n",
    "    classes -- tensor of shape (num_boxes), boxes classes\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    iou_threshold -- real value, intersection over union threshold\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    classes -- tensor of shape (None, ), predicted class for each box\n",
    "    \n",
    "    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')\n",
    "    \n",
    "    nms_indices = tf.image.non_max_suppression(boxes, \n",
    "                                               scores, \n",
    "                                               max_boxes_tensor, \n",
    "                                               iou_threshold)\n",
    "    \n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes, nms_indices)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - YOLO Evaluation  \n",
    "We'll treat the model's output and pass to non-max supression function to get the final classification and localization for each object in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    \n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "    \n",
    "    box_mins[...,1]\n",
    "    box_mins[...,0]\n",
    "    box_maxes[...,1]\n",
    "    box_maxes[...,0]\n",
    "    \n",
    "    boxes = tf.concat([box_mins[...,1:2],    # y1\n",
    "                       box_mins[...,0:1],    # x1\n",
    "                       box_maxes[...,1:2],   # y2\n",
    "                       box_maxes[...,0:1]],  # x2\n",
    "                      axis=-1)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-baa7fe688d21f2dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape, max_boxes=10, score_threshold=0.6, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Converts the output of YOLO encoding to your predicted boxes along with their scores, box coordinates and classes.\n",
    "    \n",
    "    Arguments:\n",
    "    yolo_outputs -- output of the encoding model, contains 4 tensors:\n",
    "                    box_xy: tensor of shape (None, 19, 19, 5, 2), center cordinates (x,y) of each box\n",
    "                    box_wh: tensor of shape (None, 19, 19, 5, 2), width and height (w,h) of each box\n",
    "                    box_confidence: tensor of shape (None, 19, 19, 5, 1), propability of containing an object for each box\n",
    "                    box_class_probs: tensor of shape (None, 19, 19, 5, 80), classes probabilities for each box\n",
    "    image_shape -- tensor of shape (2,) containing the input shape (must be float32)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    score_threshold -- real value, score threshold\n",
    "    iou_threshold -- real value, intersection over union threshold\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    classes -- tensor of shape (None,), predicted class for each box\n",
    "    \"\"\"\n",
    "    \n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "    \n",
    "    # Converting boxes box_xy and box_wh to corner coordinates\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    # Filtering boxes based on score\n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, score_threshold)\n",
    "    \n",
    "    # Scaling boxes back to original image shape\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    \n",
    "    # Applying non-max supression\n",
    "    scores, boxes, classes = non_max_suppression(boxes, \n",
    "                                                 scores, \n",
    "                                                 classes, \n",
    "                                                 max_boxes, \n",
    "                                                 iou_threshold)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - Defining Classes, Anchors and Image Shape\n",
    "\n",
    "- The information on the 80 classes and 5 boxes is gathered in two files: \"coco_classes.txt\" and \"yolo_anchors.txt\".\n",
    "- The yolo model was trained with input images with size of 608 x 608."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "model_image_size = (608, 608)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Loading the Pre-trained Model\n",
    "\n",
    "We'll load an existing pre-trained YOLO model developed using the **yad2k** implementation from Allan Zelener github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_model(\"model_data/\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Output Treatment\n",
    "\n",
    "The output of `yolo_model` is a (m, 19, 19, 5, 85) tensor. We'll use the function `yolo_head` from **yad2k** to format the encoding of the model into 4 tensors, so we can use as input to our `yolo_eval` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-4'></a>\n",
    "### 3.4 - Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll implement the `predict` function, which runs the graph to test YOLO on an image to compute `out_scores`, `out_boxes`, `out_classes`.\n",
    "\n",
    "The code below also uses the following function from **yad2k**:\n",
    "\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "    \n",
    "which opens the image file and scales, reshapes and normalizes the image. It returns the outputs:\n",
    "- image: a python (PIL) representation of your image used for drawing boxes.\n",
    "- image_data: a numpy-array representing the image. This will be the input to the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file):\n",
    "    \"\"\"\n",
    "    Runs the graph to predict boxes for \"image_file\". Prints and plots the predictions.\n",
    "    \n",
    "    Arguments:\n",
    "    image_file -- name of an image stored in the \"images\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
    "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
    "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
    "    \n",
    "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocessing the image\n",
    "    image, image_data = preprocess_image(\"samples/\" + image_file, model_image_size = (608, 608))\n",
    "    \n",
    "    # Predicting the outputs\n",
    "    yolo_model_outputs = yolo_model(image_data)\n",
    "    \n",
    "    # Treating the models outputs\n",
    "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
    "    \n",
    "    # Applying non-max supression\n",
    "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1], image.size[0]], 10, 0.3, 0.5)\n",
    "\n",
    "    # Printing predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), \"samples/\" + image_file))\n",
    "    \n",
    "    # Generating colors for drawing bounding boxes\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    \n",
    "    # Drawing bounding boxes on the image file\n",
    "    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n",
    "    \n",
    "    # Saving the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"outputs\", image_file), quality=100)\n",
    "    \n",
    "    # Displaying the results in the notebook\n",
    "    output_image = Image.open(os.path.join(\"outputs\", image_file))\n",
    "    imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "deep_venv",
   "language": "python",
   "name": "deep_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

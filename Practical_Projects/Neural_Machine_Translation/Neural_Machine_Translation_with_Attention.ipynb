{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adTDe2CTh3MU",
    "tags": []
   },
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "* We will build a Neural Machine Translation (NMT) model to translate human-readable dates (\"25th of June, 2009\") into machine-readable dates (\"2009-06-25\"), using an attention model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='0'></a>\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14508,
     "status": "ok",
     "timestamp": 1612468511651,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "RcBRMzPiiMmp",
    "outputId": "17e9a429-5bb6-4401-a23a-f8f756d6113d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from faker import Faker\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "\n",
    "from nmt_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0pkH-k0h3Mf"
   },
   "source": [
    "<a name='1.1'></a>\n",
    "## 1.1 - Overview\n",
    "\n",
    "* The dataset contains 10,000 human readable dates written in a variety of possible formats (*e.g. \"the 29th of August 1958\", \"03/30/1968\", \"24 JUNE 1987\"*) and their equivalent, standardized, machine readable dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16981,
     "status": "ok",
     "timestamp": 1612468514155,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "gwIf5l17h3Mg",
    "outputId": "1fca5fb8-3a9b-4a78-f726-7aef8e14ee41"
   },
   "outputs": [],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao4Ffrkxh3Mg"
   },
   "source": [
    "- `dataset`: a list of tuples of (human readable date, machine readable date).\n",
    "\n",
    "- `human_vocab`: a python dictionary mapping all characters used in the human readable dates to an integer-valued index.\n",
    "\n",
    "- `machine_vocab`: a python dictionary mapping all characters used in machine readable dates to an integer-valued index. \n",
    "\n",
    "- `inv_machine_vocab`: the inverse dictionary of `machine_vocab`, mapping from indices back to characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the data and map the raw text data into the index values. \n",
    "- We will set Tx=30 \n",
    "    - We assume Tx is the maximum length of the human readable date.\n",
    "    - If we get a longer input, we would have to truncate it. <br><br>\n",
    "    \n",
    "- We will set Ty=10\n",
    "    - \"YYYY-MM-DD\" is 10 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16962,
     "status": "ok",
     "timestamp": 1612468514157,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "Qdso90EBh3Mg",
    "outputId": "0a364ad8-8b25-4de3-f036-d5d8e40bdf8c"
   },
   "outputs": [],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9C0UY25h3Mh"
   },
   "source": [
    "We now have:\n",
    "- `X`:\n",
    "    - Each character in X is replaced by an index (integer) mapped to the character using `human_vocab`. \n",
    "    - Each date is padded to ensure a length of $T_x$ using a special character (< pad >). \n",
    "    - `X.shape = (m, Tx)` where m is the number of training examples in a batch. <br><br>\n",
    "    \n",
    "- `Y`:\n",
    "    - Each character is replaced by the index (integer) mapped to the character using `machine_vocab`. \n",
    "    - `Y.shape = (m, Ty)`. <br><br>\n",
    "    \n",
    "- `Xoh`: one-hot version of `X`\n",
    "    - Each index in `X` is converted to the one-hot representation.\n",
    "    - `Xoh.shape = (m, Tx, len(human_vocab))` <br><br>  \n",
    "    \n",
    "- `Yoh`: one-hot version of `Y`\n",
    "    - Each index in `Y` is converted to the one-hot representation. \n",
    "    - `Yoh.shape = (m, Ty, len(machine_vocab))`. \n",
    "    - `len(machine_vocab) = 11` since there are 10 numeric digits (0 to 9) and the `-` symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7qKvWrTh3Mh"
   },
   "source": [
    "* Let's also look at some examples of preprocessed training examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16952,
     "status": "ok",
     "timestamp": 1612468514158,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "kUOayR4gh3Mh",
    "outputId": "d20994de-bbea-4cc7-ffaf-38a05974c9db"
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "\n",
    "print(\"Source after preprocessing (one-hot):\\n\", Xoh[index])\n",
    "print()\n",
    "\n",
    "print(\"Target after preprocessing (one-hot):\\n\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94o4RYbOh3Mi"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Building the model\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - Model Overview\n",
    "\n",
    "#### Model architecture:\n",
    "\n",
    "<center><img src=\"images/attn_model.png\" width=\"60%\" height=\"60%\"></center>\n",
    "<caption><center><b>Figure 1:</b> Neural machine translation with attention</center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2TkQnykh3Mi"
   },
   "source": [
    "- We will use Attention Mechanism between encoder and decoder layers.\n",
    "\n",
    "- There are two separate LSTMs in this model: pre-attention and post-attention LSTMs.\n",
    "\n",
    "- *Pre-attention* Bi-LSTM is a Bi-directional LSTM and comes *before* the attention mechanism.\n",
    "\n",
    "    - The pre-attention Bi-LSTM goes through $T_x$ time steps. <br><br>\n",
    "\n",
    "- *Post-attention* LSTM comes *after* the attention mechanism. \n",
    "\n",
    "    - The post-attention LSTM goes through $T_y$ time steps. <br><br>\n",
    "\n",
    "- In this model, the post-attention LSTM at time $t$ does not take the previous time step's prediction $y^{\\langle t-1 \\rangle}$ as input.\n",
    "\n",
    "    - There isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYT3v7rUh3Mk"
   },
   "source": [
    "#### Pre-attention Bi-LSTM outputs\n",
    "\n",
    "- $\\overrightarrow{a}^{\\langle t \\rangle}$: hidden state of the forward-direction, pre-attention LSTM.\n",
    "    \n",
    "    \n",
    "- $\\overleftarrow{a}^{\\langle t \\rangle}$: hidden state of the backward-direction, pre-attention LSTM.\n",
    "    \n",
    "    \n",
    "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: The concatenation of the activations of both the forward-direction $\\overrightarrow{a}^{\\langle t \\rangle}$ and backward-directions $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97GUKCqwh3Mk"
   },
   "source": [
    "#### \"Energies\" $e^{\\langle t, t' \\rangle}$ computing\n",
    "- \"e\" is called the \"energies\" variable.\n",
    "- $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
    "- $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
    "- $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$ are fed into a simple neural network, which learns the function to output $e^{\\langle t, t' \\rangle}$.\n",
    "    - `RepeatVector` node is used to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times;\n",
    "    - Then `Concatenation` is used to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$;\n",
    "    - The concatenation of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$ is fed into a \"Dense\" layer, which computes $e^{\\langle t, t' \\rangle}$. <br><br>\n",
    "    \n",
    "- $e^{\\langle t, t' \\rangle}$ is passed through a softmax to compute the attention $\\alpha^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Building Self-attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16950,
     "status": "ok",
     "timestamp": 1612468514158,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "Cvop5Apyh3Mm"
   },
   "outputs": [],
   "source": [
    "# Defining shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') \n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16950,
     "status": "ok",
     "timestamp": 1612468514159,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "mZuMOnTDh3Mn"
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using repeator to repeat s_prev to be of shape (m, Tx, n_s)\n",
    "    s_prev = repeator(s_prev)\n",
    "    \n",
    "    # Usin concatenator to concatenate a and s_prev on the last axis\n",
    "    concat = concatenator([a, s_prev])\n",
    "    \n",
    "    # Using densor1 and densor2 to compute the \"energies\"\n",
    "    e = densor1(concat)\n",
    "    energies = densor2(e)\n",
    "    \n",
    "    # Using \"activator\" to compute the attention weights\n",
    "    alphas = activator(energies)\n",
    "    \n",
    "    # Using dotor to compute the context vector\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16949,
     "status": "ok",
     "timestamp": 1612468514159,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "5RHgmZrVh3Mo"
   },
   "outputs": [],
   "source": [
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state=True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16948,
     "status": "ok",
     "timestamp": 1612468514160,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "qeKbeDOvh3Mo"
   },
   "outputs": [],
   "source": [
    "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining the input layer\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    \n",
    "    # Defining initial hidden state s0 and initial cell state c0 for the post-attention LSTM\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    \n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    # Defining pre-attention Bi-LSTM\n",
    "    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(X)\n",
    "    \n",
    "    # Loop over Ty\n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(a,s)\n",
    "        _, s, c = post_activation_LSTM_cell(inputs=context, initial_state=[s,c])\n",
    "        out = output_layer(s)\n",
    "  \n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs=[X,s0,c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20837,
     "status": "ok",
     "timestamp": 1612468518050,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "psdd-Ac6h3Mp"
   },
   "outputs": [],
   "source": [
    "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20835,
     "status": "ok",
     "timestamp": 1612468518050,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "tX0vaYmPh3Mq",
    "outputId": "336b9248-70b0-4379-be95-95366874c02a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4 - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20835,
     "status": "ok",
     "timestamp": 1612468518051,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "sBFRJ49rh3Ms"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=.005, beta_1=.9, beta_2=.999, decay=.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20833,
     "status": "ok",
     "timestamp": 1612468518051,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "USFiNKYhh3Mt"
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47944,
     "status": "ok",
     "timestamp": 1612468545172,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "tPuwY45bh3Mt",
    "outputId": "ec9dfc4c-1dcb-4577-d872-474f79c60d5f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit([Xoh, s0, c0], outputs, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUikskCoh3Mt"
   },
   "source": [
    "While training you can see the loss as well as the accuracy on each of the 10 positions of the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(history.history['loss'], c='k')\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.xlabel('Epochs', fontsize=13)\n",
    "plt.ylabel('Erro', fontsize=13)\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 - Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53835,
     "status": "ok",
     "timestamp": 1612468551077,
     "user": {
      "displayName": "Mubsi K",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip7OjOkdNkKxKDyWEQAq1o8ccGN_HrBTGdqjgQ=s64",
      "userId": "08094225471505108399"
     },
     "user_tz": -300
    },
    "id": "rQ8sd_cuh3Mv",
    "outputId": "c37e92ac-5c60-4caf-b843-6aaeaa37be25"
   },
   "outputs": [],
   "source": [
    "examples = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s_0 = np.zeros((1, n_s))\n",
    "c_0 = np.zeros((1, n_s))\n",
    "\n",
    "for example in examples:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    \n",
    "    prediction = model.predict([source, s_0, c_0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XIxtN4xh3Mv"
   },
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Visualizing Attention\n",
    "\n",
    "One advantage of the attention model is that each part of the output (such as the month) knows it needs to depend only on a small part of the input (the characters in the input giving the month). We can visualize what each part of the output is looking at which part of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrP893IFh3Mv"
   },
   "source": [
    "Lets now visualize the attention values of the network. We'll propagate an example through the network, then visualize the values of $\\alpha^{\\langle t, t' \\rangle}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbcprBCPh3Mv"
   },
   "source": [
    "The function `attention_map()` pulls out the attention values from your model and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(modelx, input_vocabulary, inv_output_vocabulary, text, Tx, Ty, n_s, num = 7):\n",
    "    \"\"\"\n",
    "    Plot the attention map\n",
    "    \"\"\"\n",
    "   \n",
    "    # Recreating part of the model \n",
    "    X = modelx.inputs[0] \n",
    "    s0 = modelx.inputs[1] \n",
    "    c0 = modelx.inputs[2] \n",
    "    s = s0\n",
    "    c = s0\n",
    "    \n",
    "    a = modelx.layers[2](X)  # pre-attention bi-LSTM\n",
    "    outputs = []\n",
    "\n",
    "    for t in range(Ty):\n",
    "        s_prev = s\n",
    "        s_prev = modelx.layers[3](s_prev)    # repeat vector\n",
    "        concat = modelx.layers[4]([a, s_prev])    # concatenation\n",
    "        e = modelx.layers[5](concat)     # dense 1\n",
    "        energies = modelx.layers[6](e)    # dense 2\n",
    "        alphas = modelx.layers[7](energies) # softmax\n",
    "        context = modelx.layers[8]([alphas, a]) \n",
    "        s, _, c = modelx.layers[10](context, initial_state = [s, c]) # post-attention LSTM\n",
    "        outputs.append(energies)\n",
    "\n",
    "    f = Model(inputs = [X, s0, c0], outputs = outputs)  \n",
    "    \n",
    "    # Converting 'text' to its one-hot representation\n",
    "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
    "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
    "\n",
    "    # Building the attention map\n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    r = f([encoded, s0, c0])\n",
    " \n",
    "    attention_map = np.zeros((Ty, Tx))\n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0, t_prime]\n",
    "\n",
    "    # Normalizing attention map\n",
    "    row_max = attention_map.max(axis=1)\n",
    "    attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = modelx.predict([encoded, s0, c0])\n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "        # Selecting the index with max probability for each element sequence\n",
    "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
    "    \n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "    \n",
    "    # geting the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = Ty\n",
    "    \n",
    "    # plotting the attention_map\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # adding image\n",
    "    img = ax.imshow(attention_map[:,:len(text)], cmap='Blues')\n",
    "\n",
    "    # adding labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text)\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(list(text))\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "    \n",
    "    # adding colorbar\n",
    "    x0 = ax.get_position().x1 + .02\n",
    "    y0 = ax.get_position().y0\n",
    "    w = .02\n",
    "    h = ax.get_position().height\n",
    "    \n",
    "    cax = fig.add_axes([x0, y0, w, h])\n",
    "    cbar =  fig.colorbar(img, cax=cax)\n",
    "    cbar.ax.set_ylabel('Alpha Values', rotation=-90, va=\"bottom\")\n",
    "\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", Tx, Ty, n_s = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_venv",
   "language": "python",
   "name": "deep_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks - Step by Step\n",
    "\n",
    "- In recent years, neural networks have become much deeper, with state-of-the-art networks evolving from having just a few layers (e.g., AlexNet) to over a hundred layers. There are a lot of benefits of using a very deep network. However, it doesn't always help. \n",
    "\n",
    "- A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow. More specifically, during gradient descent, as you backpropagate from the final layer back to the first one, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode,\" from gaining very large values).     \n",
    "    \n",
    "- During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds, as shown below:\n",
    "\n",
    "<center> <img src=\"images/vanishing_grad_kiank.png\" width=\"50%\" height=\"50%\"> </center>\n",
    "<caption> <center> <b> Figure 1 </b>: Vanishing gradient. The speed of learning decreases very rapidly for the shallower layers as the network trains </center> </caption>\n",
    "<br>\n",
    "This problem was solved by He et al. that introduced the Residual Networks in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Building a Residual Network\n",
    "\n",
    "In ResNets, a \"shortcut\" or a \"skip connection\" allows the model to skip layers:  \n",
    "\n",
    "<center> <img src=\"images/skip_connection_kiank.png\" width=\"50%\" height=\"50%\"> </center>\n",
    "<caption> <center> <b> Figure 2 </b>: A ResNet block showing a skip-connection <br> </center> </caption>\n",
    "\n",
    "- The image on the left shows the \"main path\" through the network. The skip connection adds a shortcut to this path, as we can see at the image on the right. By stacking these ResNet blocks on top of each other, you can form a very deep network. \n",
    "\n",
    "- The addition of the skip connection can also makes it very easy for the block to learn the identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance.  \n",
    "    - On that note, there is also some evidence that the ease of learning an identity function accounts for ResNets' remarkable performance even more than skip connections help with vanishing gradients.\n",
    "\n",
    "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are or not the same: \"identity block\" and the \"convolutional block\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - The Identity Block\n",
    "\n",
    "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation ($a^{[l]}$) has the same dimension as the output activation ($a^{[l+2]}$).\n",
    "\n",
    "<center> <img src=\"images/idblock2_kiank.png\" width=\"60%\" height=\"60%\"> </center>\n",
    "<caption> <center> <b> Figure 3 </b>: Identity block. Skip connection \"skips over\" 2 layers. </center> </caption>\n",
    "<br>\n",
    "<center> <img src=\"images/idblock3_kiank.png\" width=\"60%\" height=\"60%\"> </center>\n",
    "<caption> <center> <b> Figure 4 </b>: Identity block. Skip connection \"skips over\" 3 layers. </center> </caption>\n",
    "<br>\n",
    "The upper path is the \"shortcut path.\" The lower path is the \"main path.\" In this diagram, notice the CONV2D and ReLU steps in each layer. To speed up training, a BatchNorm step has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, n_f, training=True, initializer = random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block from figure 4.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    n_f -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_f1, n_f2, n_f3 = n_f\n",
    "    \n",
    "    ## Main path\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # Sequence 1\n",
    "    X = Conv2D(filters = n_f1, \n",
    "               kernel_size = 1, \n",
    "               strides = (1,1), \n",
    "               padding = 'valid', \n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Sequence 2\n",
    "    X = Conv2D(filters = n_f2, \n",
    "               kernel_size = f, \n",
    "               strides = (1,1), \n",
    "               padding = 'same', \n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    # Sequence 3\n",
    "    X = Conv2D(filters = n_f3, \n",
    "               kernel_size = 1, \n",
    "               strides = (1,1), \n",
    "               padding = 'valid', \n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    # Adding the input X\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)  \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - The Convolutional Block\n",
    "\n",
    "When the input and output dimensions don't match up, we use the convolutional block. To resize the input $x$ dimensions, we implement a CONV2D layer in the shortcut path. \n",
    "\n",
    "<center> <img src=\"images/convblock_kiank.png\" width=\"60%\" height=\"60%\"> </center>\n",
    "<caption> <center> <b>Figure 5 </b>: Convolutional block </center> </caption>\n",
    " \n",
    "- The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function to reduce the dimension of the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, n_f, s=2, training=True, initializer = glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block from figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_f1, n_f2, n_f3 = n_f\n",
    "    \n",
    "    ## Main path\n",
    "    X_shortcut = X\n",
    "\n",
    "    # Sequence 1\n",
    "    X = Conv2D(filters = n_f1, \n",
    "               kernel_size = 1, \n",
    "               strides = (s,s), \n",
    "               padding='valid', \n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Sequence 2\n",
    "    X = Conv2D(filters = n_f2, \n",
    "               kernel_size = f, \n",
    "               strides = (1,1), \n",
    "               padding='same', \n",
    "               kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Sequence 3\n",
    "    X = Conv2D(filters = n_f3, \n",
    "               kernel_size = 1, \n",
    "               strides = (1,1), \n",
    "               padding='valid', \n",
    "               kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    # Shortcut path \n",
    "    X_shortcut = Conv2D(filters = n_f3, \n",
    "                        kernel_size = 1, \n",
    "                        strides = (s,s), \n",
    "                        padding='valid', \n",
    "                        kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training) \n",
    "    \n",
    "    # Adding the main and shortcut paths output \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>  \n",
    "## 2 - Building a ResNet Model\n",
    "\n",
    "Using the blocks implemented before, we will build the ResNet-50, as shown in the figure below.\n",
    "\n",
    "<center> <img src=\"images/resnet_kiank.png\" width=\"75%\" height=\"75%\"> </center>\n",
    "<caption> <center> <b> Figure 5 </b>:  ResNet-50 model </center> </caption>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the ResNet50.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # Pooling layer\n",
    "    X = AveragePooling2D(pool_size=(2,2))(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Creating the model\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_venv",
   "language": "python",
   "name": "deep_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
